<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>

# LASSO
#### 王君銘 吴艳辉

## 简单线性回归
在做统计分析时，为了解释变量之间的关系，我们最常用的方法是假设解释变量和被解释变量线性相关，即$$y=\beta^Tx$$。为了取得合适的$$\widehat\beta$$，使得$$y$$与$$\widehat y$$之间的差距尽可能的小，通常情况下我们会使用最小二乘法求解最优解，即通过最小化误差平方和来求得$$\widehat\beta$$的值

$$\widehat\beta=\arg \min _{\beta} \sum_{i=1}^{N}\left(y_{i}-\beta^{T} x_{i}\right)=\left(X^{T} X\right)^{-1} X^{T}y$$

在使用最小二乘法时通常要求样本数要大于变量数，即要求$$N>p$$。从上式可看到该方法的求解过程需要矩阵的逆，如果$$p>N$$导致其协方差矩阵不可逆。这时目标函数最小化导数为零时，方程有无数解，这样就没有办法求出最优解，这会导致模型的过度拟合。

## 正则化
为了防止模型的过度拟合，我们需要对其进行正则化，即给相应的目标函数做出一些限制，使得其最优解的空间变小。

$$\widehat{\beta}=\arg \min _{\beta} \sum_{i=1}^{N}\left(y_{i}-\beta^{T} x_{i}\right)+P_{\lambda}(|\beta|)$$

$$P_{\lambda}(|\beta|)=\lambda \sum_{j=1}^{d}\left|\beta_{j}\right|^{m}$$

上式中的$$P_{\lambda}(|\beta|)$$即为相应的限制，
其中$$m$$的取值决定了限制的范围。
当$$m=1$$时，即为Lasso回归，
当$$m=2$$时，即为Ridge回归。


## Lasso
Lasso是由1996年由Robert Tibshirani提出的，全称为Least absolute shrinkage and selection operator。

$$
\widehat{\beta}^{L}=\arg \min _{\beta}\left\{\sum_{i=1}^{N}\left(y_{i}-\beta_{0}-\sum_{j=1}^{p} \beta_{j} x_{i j}\right)^{2}+\lambda \sum_{j=1}^{p}\left|\beta_{j}\right|\right\}
$$

该方法通过在残差平方和最小化的计算中加入$$l_1$$ loss作为约束，得到一个较精炼的模型,该模型能够压缩一些回归系数，使得回归系数的绝对值之和小于某个固定值，并且在$$\lambda$$充分大时,可以把某些回归系数精确地收缩到零。该模型保留了子集收缩的优点，是一种处理具有复共线性数据的有偏估计。

<img src="/assets/lasso.png" width="50%" height="50%"/>

可以看到lasso的约束域为正方形，因此其等高线可能存在与坐标轴的切点，使得部分维度的特征权重为0，从而达到变量选择的效果，将不具有显著性的变量的系数压缩到0，从而将不显著的变量舍弃。


## LASSO应用

1. 防止模型的回归系数过大，造成过度拟合。
2. 适用于高维统计。高维数据是指数据的维数很高，远大于样本量，其明显表现是，相对于空间维数，样本量显得非常稀疏。对于高维数据带来的过度拟合问题，其解决思路为一是增加样本样，二是减少样本特征。但是现实世界获取的样本量有限，因此只能通过减少样本特征对模型进行降维。因为lasso可以使部分变量系数变为0，可以运用lasso对模型进行特征选择，减少样本特征，从而实现降维降维。
3. 将lasso应用于回归，可以在参数估计的同时实现变量的选择，较好的解决回归分析中的多重共线性的。当$$\lambda$$足够大时，可以通过lasso进行变量选择，减少模型的复杂度，产生稀疏模型（sparse model)，即只有一些变量子集的模型。

## LASSO的python实现
Lasso在python中主要通过slearn库中的linear_model中的lasso代码进行实现。
```python
import numpy as np 
import matplotlib.pyplot as plt
from sklearn.linear_model import Lasso,LassoCV,LassoLarsCV  

```


```python
# 样本数据集，第一列为x，第二列为y，在x和y之间建立回归模型
data=np.random.randn(30,2)
#随机生成X和y矩阵
dataMat = np.array(data)
X = dataMat[:,0:1]   
y = dataMat[:,1]   
```


```python
model = Lasso(alpha=0.01)  # 调节alpha可以实现对拟合的程度

model.fit(X, y)   # 线性回归建模
print('系数矩阵:\n',model.coef_)
print('线性回归模型:\n',model)

predicted = model.predict(X)

# 绘图
plt.scatter(X, y, marker='x')
plt.plot(X, predicted,c='r')

plt.xlabel("x")
plt.ylabel("y")

plt.show()

```

    系数矩阵:
     [0.29262326]
    线性回归模型:
     Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000,
       normalize=False, positive=False, precompute=False, random_state=None,
       selection='cyclic', tol=0.0001, warm_start=False)

![png](/assets/output_2_1.png)




```python

```

## lasso的challenge实现
从GSS中下载数据，被解释变量为工作状态workstate，解释变量有收入、声望等一系列变量

### 数据处理

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import os 
import re
import matplotlib.pyplot as plt
import seaborn as sns
```



```python
da = pd.read_csv('/Users/songmuqing/Desktop/data.csv')
```


```python
da.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>INCOME72</th>
      <th>year</th>
      <th>id</th>
      <th>wrkstat</th>
      <th>occ</th>
      <th>prestige</th>
      <th>industry</th>
      <th>OCC10</th>
      <th>occindv</th>
      <th>PRESTG10</th>
      <th>...</th>
      <th>padotdat</th>
      <th>padotpeo</th>
      <th>padotthn</th>
      <th>padotged</th>
      <th>padotsvp</th>
      <th>padotpre</th>
      <th>libsoc</th>
      <th>colcom</th>
      <th>gunlaw</th>
      <th>trust</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>$6000 TO</td>
      <td>1972</td>
      <td>1</td>
      <td>WORKING</td>
      <td>205.0</td>
      <td>50.0</td>
      <td>609.0</td>
      <td>Wholesal</td>
      <td>Verbatim</td>
      <td>45.0</td>
      <td>...</td>
      <td>2.84</td>
      <td>5.14</td>
      <td>7.96</td>
      <td>3.81</td>
      <td>4.97</td>
      <td>43.4</td>
      <td>NOT REMO</td>
      <td>NOT FIRE</td>
      <td>favor</td>
      <td>depends</td>
    </tr>
    <tr>
      <th>1</th>
      <td>$8000 TO</td>
      <td>1972</td>
      <td>2</td>
      <td>retired</td>
      <td>441.0</td>
      <td>45.0</td>
      <td>338.0</td>
      <td>First-li</td>
      <td>Verbatim</td>
      <td>50.0</td>
      <td>...</td>
      <td>1.97</td>
      <td>5.59</td>
      <td>7.18</td>
      <td>4.37</td>
      <td>6.61</td>
      <td>48.3</td>
      <td>NOT REMO</td>
      <td>fired</td>
      <td>favor</td>
      <td>CAN TRUS</td>
    </tr>
    <tr>
      <th>2</th>
      <td>$8000 TO</td>
      <td>1972</td>
      <td>3</td>
      <td>WORKING</td>
      <td>270.0</td>
      <td>44.0</td>
      <td>718.0</td>
      <td>Real est</td>
      <td>NaN</td>
      <td>49.0</td>
      <td>...</td>
      <td>4.01</td>
      <td>6.03</td>
      <td>3.03</td>
      <td>3.01</td>
      <td>4.98</td>
      <td>30.2</td>
      <td>NOT REMO</td>
      <td>fired</td>
      <td>favor</td>
      <td>Can't be</td>
    </tr>
    <tr>
      <th>3</th>
      <td>$10000 T</td>
      <td>1972</td>
      <td>4</td>
      <td>WORKING</td>
      <td>1.0</td>
      <td>57.0</td>
      <td>319.0</td>
      <td>Accounta</td>
      <td>Verbatim</td>
      <td>60.0</td>
      <td>...</td>
      <td>1.29</td>
      <td>3.33</td>
      <td>7.99</td>
      <td>5.06</td>
      <td>7.81</td>
      <td>60.1</td>
      <td>NOT REMO</td>
      <td>fired</td>
      <td>favor</td>
      <td>Can't be</td>
    </tr>
    <tr>
      <th>4</th>
      <td>$17500 T</td>
      <td>1972</td>
      <td>5</td>
      <td>KEEPING</td>
      <td>385.0</td>
      <td>40.0</td>
      <td>448.0</td>
      <td>Telephon</td>
      <td>Verbatim</td>
      <td>31.0</td>
      <td>...</td>
      <td>2.22</td>
      <td>7.97</td>
      <td>0.21</td>
      <td>3.95</td>
      <td>6.97</td>
      <td>41.5</td>
      <td>NOT REMO</td>
      <td>NOT FIRE</td>
      <td>favor</td>
      <td>Can't be</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 58 columns</p>
</div>




```python
da.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 1613 entries, 0 to 1612
    Data columns (total 58 columns):
    INCOME72         1474 non-null object
    year             1613 non-null int64
    id               1613 non-null int64
    wrkstat          1613 non-null object
    occ              1451 non-null float64
    prestige         1447 non-null float64
    industry         1451 non-null float64
    OCC10            1446 non-null object
    occindv          702 non-null object
    PRESTG10         1279 non-null float64
    PRESTG105PLUS    1279 non-null float64
    marital          1613 non-null object
    agewed           1395 non-null float64
    divorce          1261 non-null object
    spwrksta         1158 non-null object
    spocc            1033 non-null float64
    sppres           1027 non-null float64
    PAIND16          1328 non-null float64
    sibs             1606 non-null float64
    childs           1613 non-null object
    age              1608 non-null object
    educ             1608 non-null float64
    paeduc           1071 non-null float64
    maeduc           1254 non-null float64
    speduc           1127 non-null float64
    degree           1590 non-null object
    padeg            1129 non-null object
    madeg            1290 non-null object
    spdeg            1110 non-null object
    sex              1613 non-null object
    race             1613 non-null object
    RES16            1610 non-null object
    REG16            1613 non-null object
    MOBILE16         1562 non-null object
    INCOM16          1591 non-null object
    hompop           1613 non-null int64
    babies           1613 non-null int64
    preteen          1613 non-null int64
    teens            1613 non-null object
    adults           1613 non-null object
    earnrs           1580 non-null float64
    size             1613 non-null int64
    dotdata          1430 non-null float64
    dotpeop          1430 non-null float64
    dotthng          1430 non-null float64
    dotged           1430 non-null float64
    dotsvp           1430 non-null float64
    dotpres          1430 non-null float64
    padotdat         1337 non-null float64
    padotpeo         1337 non-null float64
    padotthn         1337 non-null float64
    padotged         1337 non-null float64
    padotsvp         1337 non-null float64
    padotpre         1337 non-null float64
    libsoc           1495 non-null object
    colcom           1497 non-null object
    gunlaw           1562 non-null object
    trust            1597 non-null object
    dtypes: float64(27), int64(6), object(25)
    memory usage: 731.0+ KB



```python
def func(x):
    try:
        return re.search('[\d]+',x).group()
    except:
        return np.nan
```


```python
da['INCOME72']  = da['INCOME72'].map(func)
```


```python
pd.unique(da['wrkstat'])
```




    array(['WORKING', 'retired', 'KEEPING', 'school', 'UNEMPL', 'TEMP NOT',
           'other'], dtype=object)




```python
pd.unique(da['educ'])
```




    array([16., 10., 12., 17., 14., 13.,  6.,  9.,  8., 11.,  7., 15., 20.,
           18.,  3.,  2.,  4.,  5., 19.,  1., nan,  0.])




```python
#WORKING   KEEPING  retired  TEMP NOT  school  UNEMPL  other     
da['wrkstat'] = da['wrkstat'].map({'WORKING':1,'retired':2,'KEEPING':3,'school':4,'UNEMPL':5,'TEMP NOT':6,'other':7})
```


```python
da['educ'].corr(da['wrkstat'])
```




    -0.1438783531869788




```python
da.groupby('wrkstat')['educ'].describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>wrkstat</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>867.0</td>
      <td>12.059977</td>
      <td>3.209556</td>
      <td>0.0</td>
      <td>11.0</td>
      <td>12.0</td>
      <td>14.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>144.0</td>
      <td>8.729167</td>
      <td>4.311667</td>
      <td>0.0</td>
      <td>6.0</td>
      <td>8.0</td>
      <td>12.0</td>
      <td>18.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>432.0</td>
      <td>10.673611</td>
      <td>3.085397</td>
      <td>0.0</td>
      <td>9.0</td>
      <td>12.0</td>
      <td>12.0</td>
      <td>18.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>58.0</td>
      <td>13.637931</td>
      <td>2.182050</td>
      <td>10.0</td>
      <td>12.0</td>
      <td>13.0</td>
      <td>15.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>46.0</td>
      <td>10.847826</td>
      <td>3.596093</td>
      <td>2.0</td>
      <td>9.0</td>
      <td>12.0</td>
      <td>12.0</td>
      <td>18.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>38.0</td>
      <td>9.842105</td>
      <td>3.192274</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>11.0</td>
      <td>12.0</td>
      <td>15.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>23.0</td>
      <td>9.826087</td>
      <td>3.069678</td>
      <td>3.0</td>
      <td>8.0</td>
      <td>11.0</td>
      <td>12.0</td>
      <td>15.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
def int_func(x):
    try:
        return int(x)
    except:
        return np.nan
```


```python
da['age'] = da['age'].map(int_func)
```


```python
da['age'].corr(da['wrkstat'])
```


 


```python
da.groupby('wrkstat')['age'].describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>wrkstat</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>KEEPING</th>
      <td>431.0</td>
      <td>47.090487</td>
      <td>17.503851</td>
      <td>20.0</td>
      <td>31.00</td>
      <td>46.0</td>
      <td>61.00</td>
      <td>88.0</td>
    </tr>
    <tr>
      <th>TEMP NOT</th>
      <td>38.0</td>
      <td>47.421053</td>
      <td>14.057087</td>
      <td>20.0</td>
      <td>36.25</td>
      <td>47.5</td>
      <td>58.50</td>
      <td>72.0</td>
    </tr>
    <tr>
      <th>UNEMPL</th>
      <td>46.0</td>
      <td>34.782609</td>
      <td>15.170019</td>
      <td>19.0</td>
      <td>24.25</td>
      <td>27.5</td>
      <td>44.75</td>
      <td>74.0</td>
    </tr>
    <tr>
      <th>WORKING</th>
      <td>868.0</td>
      <td>41.447005</td>
      <td>13.864835</td>
      <td>18.0</td>
      <td>29.00</td>
      <td>42.0</td>
      <td>52.00</td>
      <td>84.0</td>
    </tr>
    <tr>
      <th>other</th>
      <td>24.0</td>
      <td>49.208333</td>
      <td>17.670853</td>
      <td>20.0</td>
      <td>39.75</td>
      <td>53.5</td>
      <td>61.50</td>
      <td>82.0</td>
    </tr>
    <tr>
      <th>retired</th>
      <td>141.0</td>
      <td>70.007092</td>
      <td>7.500949</td>
      <td>48.0</td>
      <td>65.00</td>
      <td>70.0</td>
      <td>75.00</td>
      <td>88.0</td>
    </tr>
    <tr>
      <th>school</th>
      <td>58.0</td>
      <td>23.741379</td>
      <td>6.370327</td>
      <td>18.0</td>
      <td>20.00</td>
      <td>22.0</td>
      <td>25.00</td>
      <td>53.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.unique(da['degree'])
```




    array(['bachelor', 'LT HIGH', 'HIGH SCH', 'graduate', 'JUNIOR C', nan],
          dtype=object)




```python
da['degree'] = da['degree'].map({'JUNIOR':1,'HIGH SCH':2,'LT HIGH':3,'graduate':4,'bachelor':5})
```


```python
da['degree'].corr(da['wrkstat'])
```




    -0.042913142857476674




```python
da.groupby('wrkstat')['degree'].describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>wrkstat</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>841.0</td>
      <td>2.725327</td>
      <td>0.957148</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>143.0</td>
      <td>2.874126</td>
      <td>0.669950</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>426.0</td>
      <td>2.643192</td>
      <td>0.735271</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>56.0</td>
      <td>2.500000</td>
      <td>0.934199</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>46.0</td>
      <td>2.847826</td>
      <td>0.918148</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>37.0</td>
      <td>2.567568</td>
      <td>0.502247</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>24.0</td>
      <td>2.583333</td>
      <td>0.503610</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.unique(da['earnrs'])
```




    array([ 1.,  0.,  2.,  3.,  4., nan,  5.,  6.])




```python
da['earnrs'].corr(da['wrkstat'])
```




    -0.1756014555751151




```python
da.groupby('wrkstat')['earnrs'].describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>wrkstat</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>858.0</td>
      <td>1.835664</td>
      <td>0.915208</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>142.0</td>
      <td>0.528169</td>
      <td>0.711543</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>425.0</td>
      <td>1.167059</td>
      <td>0.935589</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>50.0</td>
      <td>1.960000</td>
      <td>1.105829</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>45.0</td>
      <td>1.644444</td>
      <td>0.908434</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>36.0</td>
      <td>1.583333</td>
      <td>0.840918</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>24.0</td>
      <td>1.208333</td>
      <td>1.062367</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
corr = da.corr()
plt.subplots(figsize=(9,9))
sns.heatmap(corr,annot=False,vmax=1,square=True,cmap="Reds")
plt.show()
```


![png](output_23_0.png)


### 编码


```python
da.fillna(method='ffill',inplace=True)
da.dropna(inplace=True)
train_labels = da['wrkstat']
da = da.drop('wrkstat',axis=1)
```


```python
train,test,y_train,y_test = train_test_split(da,train_labels,test_size=0.33, random_state=42)
```


```python
print(train.shape)
print(test.shape)
```

    (1079, 57)
    (532, 57)



```python
y_test.value_counts().astype(int).plot.hist()
plt.show()
```


![png](output_28_0.png)


### 独热编码


```python
train.dtypes.value_counts()
```




    float64    29
    object     22
    int64       6
    dtype: int64




```python
train.select_dtypes('object').apply(pd.Series.nunique,axis=0)
```




    INCOME72     11
    OCC10       181
    occindv       2
    marital       5
    divorce       2
    spwrksta      7
    childs       10
    padeg         4
    madeg         5
    spdeg         5
    sex           2
    race          3
    RES16         6
    REG16        10
    MOBILE16      3
    INCOM16       5
    teens         7
    adults        7
    libsoc        2
    colcom        2
    gunlaw        2
    trust         3
    dtype: int64




```python
le = LabelEncoder()
le_count = 0
for col in train:
    if train[col].dtype == 'object':
        if len(list(train[col].unique()))<=2:
            le.fit(train[col])
            train[col] = le.transform(train[col])
            test[col] = le.transform(test[col])
            le_count+=1
print('%d columns were label encoded' % le_count)
```

    /anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      import sys
    /anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      


    6 columns were label encoded



```python
train = pd.get_dummies(train)
test = pd.get_dummies(test)
print(train.shape)
print(test.shape)
```

    (1079, 396)
    (532, 345)



```python
train,test = train.align(test,join='inner',axis=1)
print(train.shape)
print(test.shape)
```

    (1079, 318)
    (532, 318)



```python
dic = {'KEEPING':0, 'TEMP NOT':1, 'UNEMPL':2, 'WORKING':3, 'other':4, 'retired':5,'school':6}
multi_y_test = y_test.map(lambda x:dic[x])
multi_y  = y_train.map(lambda x:dic[x])
```


```python
pd.value_counts(multi_y)
```




    3    579
    0    279
    5    102
    6     42
    2     36
    1     26
    4     15
    Name: wrkstat, dtype: int64




```python
pd.value_counts(multi_y_test)
```




    3    291
    0    153
    5     41
    6     16
    1     12
    2     10
    4      9
    Name: wrkstat, dtype: int64




```python
# 模型:多分类的惩罚逻辑回归（交叉验证CV）#
from sklearn.linear_model import LogisticRegressionCV
from sklearn.preprocessing import StandardScaler
scale = StandardScaler()
X = scale.fit_transform(train)
y =multi_y
#多分类y 独立y种类假设，最优惩罚系数待选：Cs=[1e-3,1e-2,0.1,1,5,10]
clf_log_cv = LogisticRegressionCV(cv=5, random_state=0,multi_class='multinomial',Cs=[100,500,1000]).fit(X, y)
```

   


```python
#模型预测
clf_log_cv.predict(scale.transform(test))
```

    /anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.
      





    array([0, 3, 3, 0, 3, 3, 0, 3, 3, 6, 2, 3, 5, 4, 3, 3, 0, 3, 0, 0, 0, 3,
           0, 3, 3, 0, 2, 0, 3, 0, 3, 0, 5, 3, 3, 5, 0, 3, 3, 0, 1, 3, 3, 3,
           3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 2, 3, 2, 3, 5, 3, 3,
           0, 3, 3, 3, 0, 0, 0, 0, 5, 0, 6, 3, 3, 2, 1, 3, 5, 0, 3, 0, 3, 5,
           0, 0, 0, 3, 3, 0, 3, 3, 3, 1, 0, 1, 0, 0, 3, 6, 5, 3, 0, 0, 0, 3,
           1, 3, 3, 3, 0, 3, 3, 0, 3, 3, 2, 3, 3, 3, 4, 6, 3, 3, 0, 5, 3, 0,
           3, 3, 0, 3, 0, 3, 3, 4, 0, 3, 0, 4, 0, 2, 3, 0, 1, 0, 3, 3, 0, 0,
           3, 5, 0, 4, 3, 3, 3, 3, 3, 6, 0, 3, 0, 3, 3, 2, 3, 0, 5, 3, 0, 3,
           3, 5, 6, 6, 0, 3, 0, 3, 0, 0, 0, 2, 0, 2, 3, 3, 6, 0, 0, 3, 2, 0,
           0, 3, 3, 3, 3, 1, 6, 0, 3, 0, 0, 0, 6, 6, 3, 3, 4, 3, 3, 3, 0, 3,
           3, 5, 0, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 6, 0, 0, 5, 3,
           2, 3, 3, 3, 3, 0, 3, 3, 3, 5, 3, 0, 3, 5, 0, 0, 0, 0, 0, 3, 3, 3,
           0, 3, 0, 5, 2, 3, 0, 0, 5, 3, 0, 0, 3, 0, 2, 2, 3, 3, 0, 3, 3, 5,
           6, 3, 3, 0, 3, 0, 6, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 3,
           0, 5, 0, 3, 5, 1, 6, 5, 0, 0, 0, 6, 0, 3, 1, 3, 3, 1, 3, 0, 3, 4,
           0, 0, 0, 0, 3, 3, 6, 6, 3, 1, 5, 0, 3, 5, 5, 3, 3, 0, 0, 3, 3, 3,
           3, 3, 0, 3, 0, 3, 0, 5, 3, 3, 5, 0, 3, 0, 3, 3, 0, 0, 3, 3, 5, 0,
           3, 3, 3, 0, 0, 5, 3, 3, 3, 0, 0, 3, 3, 3, 3, 2, 3, 3, 4, 0, 3, 2,
           3, 3, 5, 3, 1, 3, 6, 3, 0, 0, 5, 3, 3, 3, 3, 3, 3, 0, 0, 3, 5, 3,
           3, 0, 5, 3, 0, 0, 2, 3, 5, 3, 0, 5, 0, 0, 3, 3, 0, 1, 1, 3, 3, 1,
           2, 5, 3, 3, 0, 0, 5, 3, 3, 3, 3, 0, 3, 0, 0, 0, 3, 4, 1, 6, 2, 3,
           3, 3, 0, 3, 3, 3, 3, 0, 3, 1, 0, 3, 0, 3, 1, 4, 3, 3, 3, 0, 3, 0,
           5, 3, 3, 1, 6, 3, 3, 3, 0, 3, 3, 4, 3, 5, 0, 3, 1, 0, 3, 5, 5, 1,
           3, 3, 0, 0, 3, 3, 0, 0, 3, 3, 6, 3, 3, 6, 0, 3, 4, 3, 0, 3, 3, 3,
           3, 3, 0, 0])




```python
#模型结果评估
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
pred = clf_log_cv.predict(scale.transform(test))
```

    /anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.
      import sys



```python
#cv惩罚系数选择为
print(clf_log_cv.C_)
#一共产生了七个子模型，最后概率最高的模型代表其具体分类
len(clf_log_cv.coef_)
#下面查看变量选择情况
```

    [100 100 100 100 100 100 100]





    7




```python
#'KEEPING':0
keeping_coef = pd.DataFrame()
keeping_coef['var'] = train.columns
keeping_coef['coef'] = clf_log_cv.coef_[0]
keeping_coef
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>var</th>
      <th>coef</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>year</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>id</td>
      <td>-0.729270</td>
    </tr>
    <tr>
      <th>2</th>
      <td>occ</td>
      <td>-3.954238</td>
    </tr>
    <tr>
      <th>3</th>
      <td>prestige</td>
      <td>-0.940623</td>
    </tr>
    <tr>
      <th>4</th>
      <td>industry</td>
      <td>-0.683098</td>
    </tr>
    <tr>
      <th>5</th>
      <td>occindv</td>
      <td>-3.373192</td>
    </tr>
    <tr>
      <th>6</th>
      <td>PRESTG10</td>
      <td>2.265819</td>
    </tr>
    <tr>
      <th>7</th>
      <td>PRESTG105PLUS</td>
      <td>-1.708625</td>
    </tr>
    <tr>
      <th>8</th>
      <td>agewed</td>
      <td>0.816544</td>
    </tr>
    <tr>
      <th>9</th>
      <td>divorce</td>
      <td>1.681761</td>
    </tr>
    <tr>
      <th>10</th>
      <td>spocc</td>
      <td>1.579909</td>
    </tr>
    <tr>
      <th>11</th>
      <td>sppres</td>
      <td>1.835727</td>
    </tr>
    <tr>
      <th>12</th>
      <td>PAIND16</td>
      <td>2.319816</td>
    </tr>
    <tr>
      <th>13</th>
      <td>sibs</td>
      <td>-0.420564</td>
    </tr>
    <tr>
      <th>14</th>
      <td>educ</td>
      <td>-2.118592</td>
    </tr>
    <tr>
      <th>15</th>
      <td>paeduc</td>
      <td>1.492027</td>
    </tr>
    <tr>
      <th>16</th>
      <td>maeduc</td>
      <td>-0.231173</td>
    </tr>
    <tr>
      <th>17</th>
      <td>speduc</td>
      <td>-1.733553</td>
    </tr>
    <tr>
      <th>18</th>
      <td>sex</td>
      <td>-16.372191</td>
    </tr>
    <tr>
      <th>19</th>
      <td>hompop</td>
      <td>0.360120</td>
    </tr>
    <tr>
      <th>20</th>
      <td>babies</td>
      <td>2.964755</td>
    </tr>
    <tr>
      <th>21</th>
      <td>preteen</td>
      <td>-0.061695</td>
    </tr>
    <tr>
      <th>22</th>
      <td>earnrs</td>
      <td>-7.674416</td>
    </tr>
    <tr>
      <th>23</th>
      <td>size</td>
      <td>-1.479821</td>
    </tr>
    <tr>
      <th>24</th>
      <td>dotdata</td>
      <td>-2.100946</td>
    </tr>
    <tr>
      <th>25</th>
      <td>dotpeop</td>
      <td>-1.813109</td>
    </tr>
    <tr>
      <th>26</th>
      <td>dotthng</td>
      <td>1.302033</td>
    </tr>
    <tr>
      <th>27</th>
      <td>dotged</td>
      <td>-3.675202</td>
    </tr>
    <tr>
      <th>28</th>
      <td>dotsvp</td>
      <td>-1.170860</td>
    </tr>
    <tr>
      <th>29</th>
      <td>dotpres</td>
      <td>-0.271328</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>288</th>
      <td>REG16_MIDDLE A</td>
      <td>0.253918</td>
    </tr>
    <tr>
      <th>289</th>
      <td>REG16_NEW ENGL</td>
      <td>-0.150219</td>
    </tr>
    <tr>
      <th>290</th>
      <td>REG16_SOUTH AT</td>
      <td>0.002823</td>
    </tr>
    <tr>
      <th>291</th>
      <td>REG16_W. NOR.</td>
      <td>0.253784</td>
    </tr>
    <tr>
      <th>292</th>
      <td>REG16_W. SOU.</td>
      <td>-1.120980</td>
    </tr>
    <tr>
      <th>293</th>
      <td>REG16_foreign</td>
      <td>0.629904</td>
    </tr>
    <tr>
      <th>294</th>
      <td>REG16_mountain</td>
      <td>0.640318</td>
    </tr>
    <tr>
      <th>295</th>
      <td>REG16_pacific</td>
      <td>0.150570</td>
    </tr>
    <tr>
      <th>296</th>
      <td>MOBILE16_DIFFEREN</td>
      <td>-0.006454</td>
    </tr>
    <tr>
      <th>297</th>
      <td>MOBILE16_SAME CIT</td>
      <td>0.407111</td>
    </tr>
    <tr>
      <th>298</th>
      <td>MOBILE16_SAME ST,</td>
      <td>-0.510272</td>
    </tr>
    <tr>
      <th>299</th>
      <td>INCOM16_ABOVE AV</td>
      <td>-1.339433</td>
    </tr>
    <tr>
      <th>300</th>
      <td>INCOM16_BELOW AV</td>
      <td>0.880685</td>
    </tr>
    <tr>
      <th>301</th>
      <td>INCOM16_FAR ABOV</td>
      <td>-0.313857</td>
    </tr>
    <tr>
      <th>302</th>
      <td>INCOM16_FAR BELO</td>
      <td>-0.007755</td>
    </tr>
    <tr>
      <th>303</th>
      <td>INCOM16_average</td>
      <td>0.116264</td>
    </tr>
    <tr>
      <th>304</th>
      <td>teens_0</td>
      <td>0.480353</td>
    </tr>
    <tr>
      <th>305</th>
      <td>teens_1</td>
      <td>1.472422</td>
    </tr>
    <tr>
      <th>306</th>
      <td>teens_2</td>
      <td>-1.859056</td>
    </tr>
    <tr>
      <th>307</th>
      <td>teens_3</td>
      <td>2.067859</td>
    </tr>
    <tr>
      <th>308</th>
      <td>adults_.b</td>
      <td>-0.314974</td>
    </tr>
    <tr>
      <th>309</th>
      <td>adults_1</td>
      <td>1.895183</td>
    </tr>
    <tr>
      <th>310</th>
      <td>adults_2</td>
      <td>-1.361154</td>
    </tr>
    <tr>
      <th>311</th>
      <td>adults_3</td>
      <td>-1.540107</td>
    </tr>
    <tr>
      <th>312</th>
      <td>adults_4</td>
      <td>1.597657</td>
    </tr>
    <tr>
      <th>313</th>
      <td>adults_5</td>
      <td>1.186031</td>
    </tr>
    <tr>
      <th>314</th>
      <td>adults_6</td>
      <td>1.727942</td>
    </tr>
    <tr>
      <th>315</th>
      <td>trust_CAN TRUS</td>
      <td>-0.070889</td>
    </tr>
    <tr>
      <th>316</th>
      <td>trust_Can't be</td>
      <td>-0.570973</td>
    </tr>
    <tr>
      <th>317</th>
      <td>trust_depends</td>
      <td>1.763126</td>
    </tr>
  </tbody>
</table>
<p>318 rows × 2 columns</p>
</div>




```python
# 'TEMP NOT':1,
tempnot_coef = pd.DataFrame()
tempnot_coef['var'] = train.columns
tempnot_coef['coef'] = clf_log_cv.coef_[1]
tempnot_coef
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>var</th>
      <th>coef</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>year</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>id</td>
      <td>-0.052155</td>
    </tr>
    <tr>
      <th>2</th>
      <td>occ</td>
      <td>0.292809</td>
    </tr>
    <tr>
      <th>3</th>
      <td>prestige</td>
      <td>-0.305709</td>
    </tr>
    <tr>
      <th>4</th>
      <td>industry</td>
      <td>-0.875251</td>
    </tr>
    <tr>
      <th>5</th>
      <td>occindv</td>
      <td>0.934500</td>
    </tr>
    <tr>
      <th>6</th>
      <td>PRESTG10</td>
      <td>-0.511470</td>
    </tr>
    <tr>
      <th>7</th>
      <td>PRESTG105PLUS</td>
      <td>-0.303816</td>
    </tr>
    <tr>
      <th>8</th>
      <td>agewed</td>
      <td>0.051654</td>
    </tr>
    <tr>
      <th>9</th>
      <td>divorce</td>
      <td>0.231129</td>
    </tr>
    <tr>
      <th>10</th>
      <td>spocc</td>
      <td>-0.365255</td>
    </tr>
    <tr>
      <th>11</th>
      <td>sppres</td>
      <td>0.280673</td>
    </tr>
    <tr>
      <th>12</th>
      <td>PAIND16</td>
      <td>-1.269042</td>
    </tr>
    <tr>
      <th>13</th>
      <td>sibs</td>
      <td>0.351015</td>
    </tr>
    <tr>
      <th>14</th>
      <td>educ</td>
      <td>-0.693966</td>
    </tr>
    <tr>
      <th>15</th>
      <td>paeduc</td>
      <td>0.089651</td>
    </tr>
    <tr>
      <th>16</th>
      <td>maeduc</td>
      <td>0.519670</td>
    </tr>
    <tr>
      <th>17</th>
      <td>speduc</td>
      <td>1.170221</td>
    </tr>
    <tr>
      <th>18</th>
      <td>sex</td>
      <td>1.822254</td>
    </tr>
    <tr>
      <th>19</th>
      <td>hompop</td>
      <td>-0.697575</td>
    </tr>
    <tr>
      <th>20</th>
      <td>babies</td>
      <td>-1.053306</td>
    </tr>
    <tr>
      <th>21</th>
      <td>preteen</td>
      <td>-0.525848</td>
    </tr>
    <tr>
      <th>22</th>
      <td>earnrs</td>
      <td>2.011957</td>
    </tr>
    <tr>
      <th>23</th>
      <td>size</td>
      <td>0.920622</td>
    </tr>
    <tr>
      <th>24</th>
      <td>dotdata</td>
      <td>0.520298</td>
    </tr>
    <tr>
      <th>25</th>
      <td>dotpeop</td>
      <td>0.875389</td>
    </tr>
    <tr>
      <th>26</th>
      <td>dotthng</td>
      <td>-0.815879</td>
    </tr>
    <tr>
      <th>27</th>
      <td>dotged</td>
      <td>-0.696037</td>
    </tr>
    <tr>
      <th>28</th>
      <td>dotsvp</td>
      <td>-0.233896</td>
    </tr>
    <tr>
      <th>29</th>
      <td>dotpres</td>
      <td>-1.267098</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>288</th>
      <td>REG16_MIDDLE A</td>
      <td>0.746240</td>
    </tr>
    <tr>
      <th>289</th>
      <td>REG16_NEW ENGL</td>
      <td>-0.381448</td>
    </tr>
    <tr>
      <th>290</th>
      <td>REG16_SOUTH AT</td>
      <td>0.083496</td>
    </tr>
    <tr>
      <th>291</th>
      <td>REG16_W. NOR.</td>
      <td>-0.641305</td>
    </tr>
    <tr>
      <th>292</th>
      <td>REG16_W. SOU.</td>
      <td>0.384881</td>
    </tr>
    <tr>
      <th>293</th>
      <td>REG16_foreign</td>
      <td>0.690636</td>
    </tr>
    <tr>
      <th>294</th>
      <td>REG16_mountain</td>
      <td>-0.869058</td>
    </tr>
    <tr>
      <th>295</th>
      <td>REG16_pacific</td>
      <td>1.246632</td>
    </tr>
    <tr>
      <th>296</th>
      <td>MOBILE16_DIFFEREN</td>
      <td>-0.397393</td>
    </tr>
    <tr>
      <th>297</th>
      <td>MOBILE16_SAME CIT</td>
      <td>-0.721062</td>
    </tr>
    <tr>
      <th>298</th>
      <td>MOBILE16_SAME ST,</td>
      <td>1.396837</td>
    </tr>
    <tr>
      <th>299</th>
      <td>INCOM16_ABOVE AV</td>
      <td>1.591412</td>
    </tr>
    <tr>
      <th>300</th>
      <td>INCOM16_BELOW AV</td>
      <td>-0.581876</td>
    </tr>
    <tr>
      <th>301</th>
      <td>INCOM16_FAR ABOV</td>
      <td>0.585464</td>
    </tr>
    <tr>
      <th>302</th>
      <td>INCOM16_FAR BELO</td>
      <td>0.799231</td>
    </tr>
    <tr>
      <th>303</th>
      <td>INCOM16_average</td>
      <td>-0.992006</td>
    </tr>
    <tr>
      <th>304</th>
      <td>teens_0</td>
      <td>0.793839</td>
    </tr>
    <tr>
      <th>305</th>
      <td>teens_1</td>
      <td>-1.068973</td>
    </tr>
    <tr>
      <th>306</th>
      <td>teens_2</td>
      <td>-0.115733</td>
    </tr>
    <tr>
      <th>307</th>
      <td>teens_3</td>
      <td>-0.950353</td>
    </tr>
    <tr>
      <th>308</th>
      <td>adults_.b</td>
      <td>0.025185</td>
    </tr>
    <tr>
      <th>309</th>
      <td>adults_1</td>
      <td>-1.156188</td>
    </tr>
    <tr>
      <th>310</th>
      <td>adults_2</td>
      <td>1.601426</td>
    </tr>
    <tr>
      <th>311</th>
      <td>adults_3</td>
      <td>-0.969536</td>
    </tr>
    <tr>
      <th>312</th>
      <td>adults_4</td>
      <td>0.118405</td>
    </tr>
    <tr>
      <th>313</th>
      <td>adults_5</td>
      <td>-0.667848</td>
    </tr>
    <tr>
      <th>314</th>
      <td>adults_6</td>
      <td>0.448077</td>
    </tr>
    <tr>
      <th>315</th>
      <td>trust_CAN TRUS</td>
      <td>0.554380</td>
    </tr>
    <tr>
      <th>316</th>
      <td>trust_Can't be</td>
      <td>-0.255410</td>
    </tr>
    <tr>
      <th>317</th>
      <td>trust_depends</td>
      <td>-0.819416</td>
    </tr>
  </tbody>
</table>
<p>318 rows × 2 columns</p>
</div>




```python
#'UNEMPL':2
unempl_coef = pd.DataFrame()
unempl_coef['var'] = train.columns
unempl_coef['coef'] = clf_log_cv.coef_[2]
unempl_coef
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>var</th>
      <th>coef</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>year</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>id</td>
      <td>0.255624</td>
    </tr>
    <tr>
      <th>2</th>
      <td>occ</td>
      <td>0.067292</td>
    </tr>
    <tr>
      <th>3</th>
      <td>prestige</td>
      <td>-0.556526</td>
    </tr>
    <tr>
      <th>4</th>
      <td>industry</td>
      <td>0.590028</td>
    </tr>
    <tr>
      <th>5</th>
      <td>occindv</td>
      <td>0.881949</td>
    </tr>
    <tr>
      <th>6</th>
      <td>PRESTG10</td>
      <td>-0.060400</td>
    </tr>
    <tr>
      <th>7</th>
      <td>PRESTG105PLUS</td>
      <td>-0.281898</td>
    </tr>
    <tr>
      <th>8</th>
      <td>agewed</td>
      <td>-0.941227</td>
    </tr>
    <tr>
      <th>9</th>
      <td>divorce</td>
      <td>-0.957518</td>
    </tr>
    <tr>
      <th>10</th>
      <td>spocc</td>
      <td>-0.383730</td>
    </tr>
    <tr>
      <th>11</th>
      <td>sppres</td>
      <td>-0.896613</td>
    </tr>
    <tr>
      <th>12</th>
      <td>PAIND16</td>
      <td>0.508220</td>
    </tr>
    <tr>
      <th>13</th>
      <td>sibs</td>
      <td>-0.044605</td>
    </tr>
    <tr>
      <th>14</th>
      <td>educ</td>
      <td>0.384360</td>
    </tr>
    <tr>
      <th>15</th>
      <td>paeduc</td>
      <td>-0.537472</td>
    </tr>
    <tr>
      <th>16</th>
      <td>maeduc</td>
      <td>-0.271672</td>
    </tr>
    <tr>
      <th>17</th>
      <td>speduc</td>
      <td>-0.433585</td>
    </tr>
    <tr>
      <th>18</th>
      <td>sex</td>
      <td>4.447049</td>
    </tr>
    <tr>
      <th>19</th>
      <td>hompop</td>
      <td>-0.002209</td>
    </tr>
    <tr>
      <th>20</th>
      <td>babies</td>
      <td>-0.655373</td>
    </tr>
    <tr>
      <th>21</th>
      <td>preteen</td>
      <td>-0.012983</td>
    </tr>
    <tr>
      <th>22</th>
      <td>earnrs</td>
      <td>2.604666</td>
    </tr>
    <tr>
      <th>23</th>
      <td>size</td>
      <td>0.717663</td>
    </tr>
    <tr>
      <th>24</th>
      <td>dotdata</td>
      <td>0.576350</td>
    </tr>
    <tr>
      <th>25</th>
      <td>dotpeop</td>
      <td>-0.198568</td>
    </tr>
    <tr>
      <th>26</th>
      <td>dotthng</td>
      <td>0.553247</td>
    </tr>
    <tr>
      <th>27</th>
      <td>dotged</td>
      <td>0.186926</td>
    </tr>
    <tr>
      <th>28</th>
      <td>dotsvp</td>
      <td>0.170468</td>
    </tr>
    <tr>
      <th>29</th>
      <td>dotpres</td>
      <td>0.461022</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>288</th>
      <td>REG16_MIDDLE A</td>
      <td>-0.511543</td>
    </tr>
    <tr>
      <th>289</th>
      <td>REG16_NEW ENGL</td>
      <td>1.712487</td>
    </tr>
    <tr>
      <th>290</th>
      <td>REG16_SOUTH AT</td>
      <td>-0.949188</td>
    </tr>
    <tr>
      <th>291</th>
      <td>REG16_W. NOR.</td>
      <td>0.355990</td>
    </tr>
    <tr>
      <th>292</th>
      <td>REG16_W. SOU.</td>
      <td>-0.268757</td>
    </tr>
    <tr>
      <th>293</th>
      <td>REG16_foreign</td>
      <td>-0.096180</td>
    </tr>
    <tr>
      <th>294</th>
      <td>REG16_mountain</td>
      <td>-0.111279</td>
    </tr>
    <tr>
      <th>295</th>
      <td>REG16_pacific</td>
      <td>-0.675256</td>
    </tr>
    <tr>
      <th>296</th>
      <td>MOBILE16_DIFFEREN</td>
      <td>0.877521</td>
    </tr>
    <tr>
      <th>297</th>
      <td>MOBILE16_SAME CIT</td>
      <td>1.382076</td>
    </tr>
    <tr>
      <th>298</th>
      <td>MOBILE16_SAME ST,</td>
      <td>-2.817044</td>
    </tr>
    <tr>
      <th>299</th>
      <td>INCOM16_ABOVE AV</td>
      <td>0.349831</td>
    </tr>
    <tr>
      <th>300</th>
      <td>INCOM16_BELOW AV</td>
      <td>-1.162612</td>
    </tr>
    <tr>
      <th>301</th>
      <td>INCOM16_FAR ABOV</td>
      <td>-0.202918</td>
    </tr>
    <tr>
      <th>302</th>
      <td>INCOM16_FAR BELO</td>
      <td>0.249685</td>
    </tr>
    <tr>
      <th>303</th>
      <td>INCOM16_average</td>
      <td>0.730488</td>
    </tr>
    <tr>
      <th>304</th>
      <td>teens_0</td>
      <td>-0.293460</td>
    </tr>
    <tr>
      <th>305</th>
      <td>teens_1</td>
      <td>0.312784</td>
    </tr>
    <tr>
      <th>306</th>
      <td>teens_2</td>
      <td>-0.387540</td>
    </tr>
    <tr>
      <th>307</th>
      <td>teens_3</td>
      <td>0.794338</td>
    </tr>
    <tr>
      <th>308</th>
      <td>adults_.b</td>
      <td>0.028485</td>
    </tr>
    <tr>
      <th>309</th>
      <td>adults_1</td>
      <td>-1.551290</td>
    </tr>
    <tr>
      <th>310</th>
      <td>adults_2</td>
      <td>0.889075</td>
    </tr>
    <tr>
      <th>311</th>
      <td>adults_3</td>
      <td>1.193547</td>
    </tr>
    <tr>
      <th>312</th>
      <td>adults_4</td>
      <td>-1.533447</td>
    </tr>
    <tr>
      <th>313</th>
      <td>adults_5</td>
      <td>-0.040857</td>
    </tr>
    <tr>
      <th>314</th>
      <td>adults_6</td>
      <td>-0.037064</td>
    </tr>
    <tr>
      <th>315</th>
      <td>trust_CAN TRUS</td>
      <td>-1.077200</td>
    </tr>
    <tr>
      <th>316</th>
      <td>trust_Can't be</td>
      <td>1.215429</td>
    </tr>
    <tr>
      <th>317</th>
      <td>trust_depends</td>
      <td>-0.383519</td>
    </tr>
  </tbody>
</table>
<p>318 rows × 2 columns</p>
</div>




```python
# 'WORKING':3
working_coef = pd.DataFrame()
working_coef['var'] = train.columns
working_coef['coef'] = clf_log_cv.coef_[3]
working_coef
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>var</th>
      <th>coef</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>year</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>id</td>
      <td>-1.567814</td>
    </tr>
    <tr>
      <th>2</th>
      <td>occ</td>
      <td>-0.616817</td>
    </tr>
    <tr>
      <th>3</th>
      <td>prestige</td>
      <td>-0.173978</td>
    </tr>
    <tr>
      <th>4</th>
      <td>industry</td>
      <td>0.895480</td>
    </tr>
    <tr>
      <th>5</th>
      <td>occindv</td>
      <td>2.618230</td>
    </tr>
    <tr>
      <th>6</th>
      <td>PRESTG10</td>
      <td>-1.177505</td>
    </tr>
    <tr>
      <th>7</th>
      <td>PRESTG105PLUS</td>
      <td>1.802192</td>
    </tr>
    <tr>
      <th>8</th>
      <td>agewed</td>
      <td>-1.038338</td>
    </tr>
    <tr>
      <th>9</th>
      <td>divorce</td>
      <td>-0.245539</td>
    </tr>
    <tr>
      <th>10</th>
      <td>spocc</td>
      <td>-1.066980</td>
    </tr>
    <tr>
      <th>11</th>
      <td>sppres</td>
      <td>-0.623826</td>
    </tr>
    <tr>
      <th>12</th>
      <td>PAIND16</td>
      <td>-1.067620</td>
    </tr>
    <tr>
      <th>13</th>
      <td>sibs</td>
      <td>1.148473</td>
    </tr>
    <tr>
      <th>14</th>
      <td>educ</td>
      <td>1.372715</td>
    </tr>
    <tr>
      <th>15</th>
      <td>paeduc</td>
      <td>0.291718</td>
    </tr>
    <tr>
      <th>16</th>
      <td>maeduc</td>
      <td>-0.277129</td>
    </tr>
    <tr>
      <th>17</th>
      <td>speduc</td>
      <td>1.064756</td>
    </tr>
    <tr>
      <th>18</th>
      <td>sex</td>
      <td>3.997214</td>
    </tr>
    <tr>
      <th>19</th>
      <td>hompop</td>
      <td>-0.429830</td>
    </tr>
    <tr>
      <th>20</th>
      <td>babies</td>
      <td>-0.102599</td>
    </tr>
    <tr>
      <th>21</th>
      <td>preteen</td>
      <td>0.163088</td>
    </tr>
    <tr>
      <th>22</th>
      <td>earnrs</td>
      <td>6.784707</td>
    </tr>
    <tr>
      <th>23</th>
      <td>size</td>
      <td>2.129462</td>
    </tr>
    <tr>
      <th>24</th>
      <td>dotdata</td>
      <td>1.908629</td>
    </tr>
    <tr>
      <th>25</th>
      <td>dotpeop</td>
      <td>1.989399</td>
    </tr>
    <tr>
      <th>26</th>
      <td>dotthng</td>
      <td>-1.792785</td>
    </tr>
    <tr>
      <th>27</th>
      <td>dotged</td>
      <td>3.703335</td>
    </tr>
    <tr>
      <th>28</th>
      <td>dotsvp</td>
      <td>1.450511</td>
    </tr>
    <tr>
      <th>29</th>
      <td>dotpres</td>
      <td>-0.691288</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>288</th>
      <td>REG16_MIDDLE A</td>
      <td>-0.646892</td>
    </tr>
    <tr>
      <th>289</th>
      <td>REG16_NEW ENGL</td>
      <td>-0.253028</td>
    </tr>
    <tr>
      <th>290</th>
      <td>REG16_SOUTH AT</td>
      <td>-0.074726</td>
    </tr>
    <tr>
      <th>291</th>
      <td>REG16_W. NOR.</td>
      <td>0.230349</td>
    </tr>
    <tr>
      <th>292</th>
      <td>REG16_W. SOU.</td>
      <td>1.918424</td>
    </tr>
    <tr>
      <th>293</th>
      <td>REG16_foreign</td>
      <td>-1.600290</td>
    </tr>
    <tr>
      <th>294</th>
      <td>REG16_mountain</td>
      <td>0.985377</td>
    </tr>
    <tr>
      <th>295</th>
      <td>REG16_pacific</td>
      <td>-0.483373</td>
    </tr>
    <tr>
      <th>296</th>
      <td>MOBILE16_DIFFEREN</td>
      <td>-0.621765</td>
    </tr>
    <tr>
      <th>297</th>
      <td>MOBILE16_SAME CIT</td>
      <td>0.056906</td>
    </tr>
    <tr>
      <th>298</th>
      <td>MOBILE16_SAME ST,</td>
      <td>0.677462</td>
    </tr>
    <tr>
      <th>299</th>
      <td>INCOM16_ABOVE AV</td>
      <td>-0.154240</td>
    </tr>
    <tr>
      <th>300</th>
      <td>INCOM16_BELOW AV</td>
      <td>0.432537</td>
    </tr>
    <tr>
      <th>301</th>
      <td>INCOM16_FAR ABOV</td>
      <td>0.199768</td>
    </tr>
    <tr>
      <th>302</th>
      <td>INCOM16_FAR BELO</td>
      <td>-0.052810</td>
    </tr>
    <tr>
      <th>303</th>
      <td>INCOM16_average</td>
      <td>-0.307720</td>
    </tr>
    <tr>
      <th>304</th>
      <td>teens_0</td>
      <td>-0.130529</td>
    </tr>
    <tr>
      <th>305</th>
      <td>teens_1</td>
      <td>-1.427299</td>
    </tr>
    <tr>
      <th>306</th>
      <td>teens_2</td>
      <td>1.100945</td>
    </tr>
    <tr>
      <th>307</th>
      <td>teens_3</td>
      <td>-0.749462</td>
    </tr>
    <tr>
      <th>308</th>
      <td>adults_.b</td>
      <td>-0.178180</td>
    </tr>
    <tr>
      <th>309</th>
      <td>adults_1</td>
      <td>1.353414</td>
    </tr>
    <tr>
      <th>310</th>
      <td>adults_2</td>
      <td>0.785093</td>
    </tr>
    <tr>
      <th>311</th>
      <td>adults_3</td>
      <td>-0.737850</td>
    </tr>
    <tr>
      <th>312</th>
      <td>adults_4</td>
      <td>-1.429325</td>
    </tr>
    <tr>
      <th>313</th>
      <td>adults_5</td>
      <td>-0.974370</td>
    </tr>
    <tr>
      <th>314</th>
      <td>adults_6</td>
      <td>-1.637768</td>
    </tr>
    <tr>
      <th>315</th>
      <td>trust_CAN TRUS</td>
      <td>-0.482986</td>
    </tr>
    <tr>
      <th>316</th>
      <td>trust_Can't be</td>
      <td>0.457755</td>
    </tr>
    <tr>
      <th>317</th>
      <td>trust_depends</td>
      <td>0.067628</td>
    </tr>
  </tbody>
</table>
<p>318 rows × 2 columns</p>
</div>




```python
#'other':4
other_coef = pd.DataFrame()
other_coef['var'] = train.columns
other_coef['coef'] = clf_log_cv.coef_[4]
other_coef
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>var</th>
      <th>coef</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>year</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>id</td>
      <td>-0.659578</td>
    </tr>
    <tr>
      <th>2</th>
      <td>occ</td>
      <td>0.396405</td>
    </tr>
    <tr>
      <th>3</th>
      <td>prestige</td>
      <td>0.106686</td>
    </tr>
    <tr>
      <th>4</th>
      <td>industry</td>
      <td>-1.251237</td>
    </tr>
    <tr>
      <th>5</th>
      <td>occindv</td>
      <td>0.579997</td>
    </tr>
    <tr>
      <th>6</th>
      <td>PRESTG10</td>
      <td>-0.238182</td>
    </tr>
    <tr>
      <th>7</th>
      <td>PRESTG105PLUS</td>
      <td>-0.013221</td>
    </tr>
    <tr>
      <th>8</th>
      <td>agewed</td>
      <td>-0.383122</td>
    </tr>
    <tr>
      <th>9</th>
      <td>divorce</td>
      <td>0.750283</td>
    </tr>
    <tr>
      <th>10</th>
      <td>spocc</td>
      <td>0.258572</td>
    </tr>
    <tr>
      <th>11</th>
      <td>sppres</td>
      <td>-0.686044</td>
    </tr>
    <tr>
      <th>12</th>
      <td>PAIND16</td>
      <td>0.044451</td>
    </tr>
    <tr>
      <th>13</th>
      <td>sibs</td>
      <td>-1.980372</td>
    </tr>
    <tr>
      <th>14</th>
      <td>educ</td>
      <td>-1.399645</td>
    </tr>
    <tr>
      <th>15</th>
      <td>paeduc</td>
      <td>0.543809</td>
    </tr>
    <tr>
      <th>16</th>
      <td>maeduc</td>
      <td>-0.599400</td>
    </tr>
    <tr>
      <th>17</th>
      <td>speduc</td>
      <td>0.799433</td>
    </tr>
    <tr>
      <th>18</th>
      <td>sex</td>
      <td>-0.093848</td>
    </tr>
    <tr>
      <th>19</th>
      <td>hompop</td>
      <td>0.759436</td>
    </tr>
    <tr>
      <th>20</th>
      <td>babies</td>
      <td>0.890059</td>
    </tr>
    <tr>
      <th>21</th>
      <td>preteen</td>
      <td>-0.862613</td>
    </tr>
    <tr>
      <th>22</th>
      <td>earnrs</td>
      <td>-0.822818</td>
    </tr>
    <tr>
      <th>23</th>
      <td>size</td>
      <td>-1.087156</td>
    </tr>
    <tr>
      <th>24</th>
      <td>dotdata</td>
      <td>0.220917</td>
    </tr>
    <tr>
      <th>25</th>
      <td>dotpeop</td>
      <td>-0.001564</td>
    </tr>
    <tr>
      <th>26</th>
      <td>dotthng</td>
      <td>0.443626</td>
    </tr>
    <tr>
      <th>27</th>
      <td>dotged</td>
      <td>0.358047</td>
    </tr>
    <tr>
      <th>28</th>
      <td>dotsvp</td>
      <td>0.004114</td>
    </tr>
    <tr>
      <th>29</th>
      <td>dotpres</td>
      <td>0.016198</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>288</th>
      <td>REG16_MIDDLE A</td>
      <td>0.135877</td>
    </tr>
    <tr>
      <th>289</th>
      <td>REG16_NEW ENGL</td>
      <td>-0.412075</td>
    </tr>
    <tr>
      <th>290</th>
      <td>REG16_SOUTH AT</td>
      <td>0.777947</td>
    </tr>
    <tr>
      <th>291</th>
      <td>REG16_W. NOR.</td>
      <td>-0.201247</td>
    </tr>
    <tr>
      <th>292</th>
      <td>REG16_W. SOU.</td>
      <td>0.572910</td>
    </tr>
    <tr>
      <th>293</th>
      <td>REG16_foreign</td>
      <td>-0.586688</td>
    </tr>
    <tr>
      <th>294</th>
      <td>REG16_mountain</td>
      <td>-0.319793</td>
    </tr>
    <tr>
      <th>295</th>
      <td>REG16_pacific</td>
      <td>0.128237</td>
    </tr>
    <tr>
      <th>296</th>
      <td>MOBILE16_DIFFEREN</td>
      <td>-0.519650</td>
    </tr>
    <tr>
      <th>297</th>
      <td>MOBILE16_SAME CIT</td>
      <td>-0.051480</td>
    </tr>
    <tr>
      <th>298</th>
      <td>MOBILE16_SAME ST,</td>
      <td>0.692230</td>
    </tr>
    <tr>
      <th>299</th>
      <td>INCOM16_ABOVE AV</td>
      <td>-0.819059</td>
    </tr>
    <tr>
      <th>300</th>
      <td>INCOM16_BELOW AV</td>
      <td>-0.128167</td>
    </tr>
    <tr>
      <th>301</th>
      <td>INCOM16_FAR ABOV</td>
      <td>0.325385</td>
    </tr>
    <tr>
      <th>302</th>
      <td>INCOM16_FAR BELO</td>
      <td>0.183061</td>
    </tr>
    <tr>
      <th>303</th>
      <td>INCOM16_average</td>
      <td>0.433525</td>
    </tr>
    <tr>
      <th>304</th>
      <td>teens_0</td>
      <td>-0.279783</td>
    </tr>
    <tr>
      <th>305</th>
      <td>teens_1</td>
      <td>-0.808921</td>
    </tr>
    <tr>
      <th>306</th>
      <td>teens_2</td>
      <td>1.199657</td>
    </tr>
    <tr>
      <th>307</th>
      <td>teens_3</td>
      <td>0.591474</td>
    </tr>
    <tr>
      <th>308</th>
      <td>adults_.b</td>
      <td>-0.033760</td>
    </tr>
    <tr>
      <th>309</th>
      <td>adults_1</td>
      <td>-0.372424</td>
    </tr>
    <tr>
      <th>310</th>
      <td>adults_2</td>
      <td>-0.406026</td>
    </tr>
    <tr>
      <th>311</th>
      <td>adults_3</td>
      <td>-0.183593</td>
    </tr>
    <tr>
      <th>312</th>
      <td>adults_4</td>
      <td>1.299186</td>
    </tr>
    <tr>
      <th>313</th>
      <td>adults_5</td>
      <td>0.806806</td>
    </tr>
    <tr>
      <th>314</th>
      <td>adults_6</td>
      <td>-0.104074</td>
    </tr>
    <tr>
      <th>315</th>
      <td>trust_CAN TRUS</td>
      <td>-0.242548</td>
    </tr>
    <tr>
      <th>316</th>
      <td>trust_Can't be</td>
      <td>0.012253</td>
    </tr>
    <tr>
      <th>317</th>
      <td>trust_depends</td>
      <td>0.631838</td>
    </tr>
  </tbody>
</table>
<p>318 rows × 2 columns</p>
</div>




```python
#'retired':5,
retired_coef = pd.DataFrame()
retired_coef['var'] = train.columns
retired_coef['coef'] = clf_log_cv.coef_[5]
retired_coef
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>var</th>
      <th>coef</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>year</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>id</td>
      <td>1.863656</td>
    </tr>
    <tr>
      <th>2</th>
      <td>occ</td>
      <td>3.877398</td>
    </tr>
    <tr>
      <th>3</th>
      <td>prestige</td>
      <td>0.759589</td>
    </tr>
    <tr>
      <th>4</th>
      <td>industry</td>
      <td>0.900220</td>
    </tr>
    <tr>
      <th>5</th>
      <td>occindv</td>
      <td>0.752917</td>
    </tr>
    <tr>
      <th>6</th>
      <td>PRESTG10</td>
      <td>-0.278073</td>
    </tr>
    <tr>
      <th>7</th>
      <td>PRESTG105PLUS</td>
      <td>0.763871</td>
    </tr>
    <tr>
      <th>8</th>
      <td>agewed</td>
      <td>2.179092</td>
    </tr>
    <tr>
      <th>9</th>
      <td>divorce</td>
      <td>-0.348276</td>
    </tr>
    <tr>
      <th>10</th>
      <td>spocc</td>
      <td>0.481991</td>
    </tr>
    <tr>
      <th>11</th>
      <td>sppres</td>
      <td>-0.344614</td>
    </tr>
    <tr>
      <th>12</th>
      <td>PAIND16</td>
      <td>0.403981</td>
    </tr>
    <tr>
      <th>13</th>
      <td>sibs</td>
      <td>0.773794</td>
    </tr>
    <tr>
      <th>14</th>
      <td>educ</td>
      <td>0.666161</td>
    </tr>
    <tr>
      <th>15</th>
      <td>paeduc</td>
      <td>-1.790453</td>
    </tr>
    <tr>
      <th>16</th>
      <td>maeduc</td>
      <td>-0.699808</td>
    </tr>
    <tr>
      <th>17</th>
      <td>speduc</td>
      <td>-1.115480</td>
    </tr>
    <tr>
      <th>18</th>
      <td>sex</td>
      <td>4.365156</td>
    </tr>
    <tr>
      <th>19</th>
      <td>hompop</td>
      <td>-1.009895</td>
    </tr>
    <tr>
      <th>20</th>
      <td>babies</td>
      <td>-1.517190</td>
    </tr>
    <tr>
      <th>21</th>
      <td>preteen</td>
      <td>0.273760</td>
    </tr>
    <tr>
      <th>22</th>
      <td>earnrs</td>
      <td>-3.621617</td>
    </tr>
    <tr>
      <th>23</th>
      <td>size</td>
      <td>-2.218836</td>
    </tr>
    <tr>
      <th>24</th>
      <td>dotdata</td>
      <td>-1.226789</td>
    </tr>
    <tr>
      <th>25</th>
      <td>dotpeop</td>
      <td>-0.723552</td>
    </tr>
    <tr>
      <th>26</th>
      <td>dotthng</td>
      <td>0.385664</td>
    </tr>
    <tr>
      <th>27</th>
      <td>dotged</td>
      <td>-0.117099</td>
    </tr>
    <tr>
      <th>28</th>
      <td>dotsvp</td>
      <td>0.040917</td>
    </tr>
    <tr>
      <th>29</th>
      <td>dotpres</td>
      <td>1.546600</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>288</th>
      <td>REG16_MIDDLE A</td>
      <td>0.259676</td>
    </tr>
    <tr>
      <th>289</th>
      <td>REG16_NEW ENGL</td>
      <td>0.141096</td>
    </tr>
    <tr>
      <th>290</th>
      <td>REG16_SOUTH AT</td>
      <td>-0.264359</td>
    </tr>
    <tr>
      <th>291</th>
      <td>REG16_W. NOR.</td>
      <td>0.606253</td>
    </tr>
    <tr>
      <th>292</th>
      <td>REG16_W. SOU.</td>
      <td>-2.033660</td>
    </tr>
    <tr>
      <th>293</th>
      <td>REG16_foreign</td>
      <td>0.285998</td>
    </tr>
    <tr>
      <th>294</th>
      <td>REG16_mountain</td>
      <td>-0.981416</td>
    </tr>
    <tr>
      <th>295</th>
      <td>REG16_pacific</td>
      <td>-0.497841</td>
    </tr>
    <tr>
      <th>296</th>
      <td>MOBILE16_DIFFEREN</td>
      <td>0.340786</td>
    </tr>
    <tr>
      <th>297</th>
      <td>MOBILE16_SAME CIT</td>
      <td>-1.417906</td>
    </tr>
    <tr>
      <th>298</th>
      <td>MOBILE16_SAME ST,</td>
      <td>1.393306</td>
    </tr>
    <tr>
      <th>299</th>
      <td>INCOM16_ABOVE AV</td>
      <td>0.786757</td>
    </tr>
    <tr>
      <th>300</th>
      <td>INCOM16_BELOW AV</td>
      <td>-0.872546</td>
    </tr>
    <tr>
      <th>301</th>
      <td>INCOM16_FAR ABOV</td>
      <td>-0.094131</td>
    </tr>
    <tr>
      <th>302</th>
      <td>INCOM16_FAR BELO</td>
      <td>-1.047582</td>
    </tr>
    <tr>
      <th>303</th>
      <td>INCOM16_average</td>
      <td>0.837514</td>
    </tr>
    <tr>
      <th>304</th>
      <td>teens_0</td>
      <td>0.709118</td>
    </tr>
    <tr>
      <th>305</th>
      <td>teens_1</td>
      <td>0.369863</td>
    </tr>
    <tr>
      <th>306</th>
      <td>teens_2</td>
      <td>-1.078043</td>
    </tr>
    <tr>
      <th>307</th>
      <td>teens_3</td>
      <td>-0.904269</td>
    </tr>
    <tr>
      <th>308</th>
      <td>adults_.b</td>
      <td>0.040527</td>
    </tr>
    <tr>
      <th>309</th>
      <td>adults_1</td>
      <td>0.883323</td>
    </tr>
    <tr>
      <th>310</th>
      <td>adults_2</td>
      <td>-1.112352</td>
    </tr>
    <tr>
      <th>311</th>
      <td>adults_3</td>
      <td>0.718407</td>
    </tr>
    <tr>
      <th>312</th>
      <td>adults_4</td>
      <td>0.003862</td>
    </tr>
    <tr>
      <th>313</th>
      <td>adults_5</td>
      <td>-0.235258</td>
    </tr>
    <tr>
      <th>314</th>
      <td>adults_6</td>
      <td>-0.007647</td>
    </tr>
    <tr>
      <th>315</th>
      <td>trust_CAN TRUS</td>
      <td>0.368301</td>
    </tr>
    <tr>
      <th>316</th>
      <td>trust_Can't be</td>
      <td>0.042478</td>
    </tr>
    <tr>
      <th>317</th>
      <td>trust_depends</td>
      <td>-1.127237</td>
    </tr>
  </tbody>
</table>
<p>318 rows × 2 columns</p>
</div>




```python
 # school':6
school_coef = pd.DataFrame()
school_coef['var'] = train.columns
school_coef['coef'] = clf_log_cv.coef_[6]
school_coef
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>var</th>
      <th>coef</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>year</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>id</td>
      <td>0.889538</td>
    </tr>
    <tr>
      <th>2</th>
      <td>occ</td>
      <td>-0.062850</td>
    </tr>
    <tr>
      <th>3</th>
      <td>prestige</td>
      <td>1.110561</td>
    </tr>
    <tr>
      <th>4</th>
      <td>industry</td>
      <td>0.423857</td>
    </tr>
    <tr>
      <th>5</th>
      <td>occindv</td>
      <td>-2.394401</td>
    </tr>
    <tr>
      <th>6</th>
      <td>PRESTG10</td>
      <td>-0.000189</td>
    </tr>
    <tr>
      <th>7</th>
      <td>PRESTG105PLUS</td>
      <td>-0.258503</td>
    </tr>
    <tr>
      <th>8</th>
      <td>agewed</td>
      <td>-0.684603</td>
    </tr>
    <tr>
      <th>9</th>
      <td>divorce</td>
      <td>-1.111840</td>
    </tr>
    <tr>
      <th>10</th>
      <td>spocc</td>
      <td>-0.504506</td>
    </tr>
    <tr>
      <th>11</th>
      <td>sppres</td>
      <td>0.434697</td>
    </tr>
    <tr>
      <th>12</th>
      <td>PAIND16</td>
      <td>-0.939805</td>
    </tr>
    <tr>
      <th>13</th>
      <td>sibs</td>
      <td>0.172259</td>
    </tr>
    <tr>
      <th>14</th>
      <td>educ</td>
      <td>1.788968</td>
    </tr>
    <tr>
      <th>15</th>
      <td>paeduc</td>
      <td>-0.089280</td>
    </tr>
    <tr>
      <th>16</th>
      <td>maeduc</td>
      <td>1.559511</td>
    </tr>
    <tr>
      <th>17</th>
      <td>speduc</td>
      <td>0.248208</td>
    </tr>
    <tr>
      <th>18</th>
      <td>sex</td>
      <td>1.834367</td>
    </tr>
    <tr>
      <th>19</th>
      <td>hompop</td>
      <td>1.019953</td>
    </tr>
    <tr>
      <th>20</th>
      <td>babies</td>
      <td>-0.526345</td>
    </tr>
    <tr>
      <th>21</th>
      <td>preteen</td>
      <td>1.026292</td>
    </tr>
    <tr>
      <th>22</th>
      <td>earnrs</td>
      <td>0.717520</td>
    </tr>
    <tr>
      <th>23</th>
      <td>size</td>
      <td>1.018067</td>
    </tr>
    <tr>
      <th>24</th>
      <td>dotdata</td>
      <td>0.101541</td>
    </tr>
    <tr>
      <th>25</th>
      <td>dotpeop</td>
      <td>-0.127995</td>
    </tr>
    <tr>
      <th>26</th>
      <td>dotthng</td>
      <td>-0.075907</td>
    </tr>
    <tr>
      <th>27</th>
      <td>dotged</td>
      <td>0.240029</td>
    </tr>
    <tr>
      <th>28</th>
      <td>dotsvp</td>
      <td>-0.261254</td>
    </tr>
    <tr>
      <th>29</th>
      <td>dotpres</td>
      <td>0.205894</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>288</th>
      <td>REG16_MIDDLE A</td>
      <td>-0.237276</td>
    </tr>
    <tr>
      <th>289</th>
      <td>REG16_NEW ENGL</td>
      <td>-0.656814</td>
    </tr>
    <tr>
      <th>290</th>
      <td>REG16_SOUTH AT</td>
      <td>0.424007</td>
    </tr>
    <tr>
      <th>291</th>
      <td>REG16_W. NOR.</td>
      <td>-0.603824</td>
    </tr>
    <tr>
      <th>292</th>
      <td>REG16_W. SOU.</td>
      <td>0.547181</td>
    </tr>
    <tr>
      <th>293</th>
      <td>REG16_foreign</td>
      <td>0.676619</td>
    </tr>
    <tr>
      <th>294</th>
      <td>REG16_mountain</td>
      <td>0.655850</td>
    </tr>
    <tr>
      <th>295</th>
      <td>REG16_pacific</td>
      <td>0.131032</td>
    </tr>
    <tr>
      <th>296</th>
      <td>MOBILE16_DIFFEREN</td>
      <td>0.326955</td>
    </tr>
    <tr>
      <th>297</th>
      <td>MOBILE16_SAME CIT</td>
      <td>0.344355</td>
    </tr>
    <tr>
      <th>298</th>
      <td>MOBILE16_SAME ST,</td>
      <td>-0.832519</td>
    </tr>
    <tr>
      <th>299</th>
      <td>INCOM16_ABOVE AV</td>
      <td>-0.415267</td>
    </tr>
    <tr>
      <th>300</th>
      <td>INCOM16_BELOW AV</td>
      <td>1.431979</td>
    </tr>
    <tr>
      <th>301</th>
      <td>INCOM16_FAR ABOV</td>
      <td>-0.499711</td>
    </tr>
    <tr>
      <th>302</th>
      <td>INCOM16_FAR BELO</td>
      <td>-0.123830</td>
    </tr>
    <tr>
      <th>303</th>
      <td>INCOM16_average</td>
      <td>-0.818065</td>
    </tr>
    <tr>
      <th>304</th>
      <td>teens_0</td>
      <td>-1.279538</td>
    </tr>
    <tr>
      <th>305</th>
      <td>teens_1</td>
      <td>1.150124</td>
    </tr>
    <tr>
      <th>306</th>
      <td>teens_2</td>
      <td>1.139769</td>
    </tr>
    <tr>
      <th>307</th>
      <td>teens_3</td>
      <td>-0.849586</td>
    </tr>
    <tr>
      <th>308</th>
      <td>adults_.b</td>
      <td>0.432718</td>
    </tr>
    <tr>
      <th>309</th>
      <td>adults_1</td>
      <td>-1.052019</td>
    </tr>
    <tr>
      <th>310</th>
      <td>adults_2</td>
      <td>-0.396062</td>
    </tr>
    <tr>
      <th>311</th>
      <td>adults_3</td>
      <td>1.519132</td>
    </tr>
    <tr>
      <th>312</th>
      <td>adults_4</td>
      <td>-0.056339</td>
    </tr>
    <tr>
      <th>313</th>
      <td>adults_5</td>
      <td>-0.074505</td>
    </tr>
    <tr>
      <th>314</th>
      <td>adults_6</td>
      <td>-0.389464</td>
    </tr>
    <tr>
      <th>315</th>
      <td>trust_CAN TRUS</td>
      <td>0.950941</td>
    </tr>
    <tr>
      <th>316</th>
      <td>trust_Can't be</td>
      <td>-0.901531</td>
    </tr>
    <tr>
      <th>317</th>
      <td>trust_depends</td>
      <td>-0.132419</td>
    </tr>
  </tbody>
</table>
<p>318 rows × 2 columns</p>
</div>




```python
print(classification_report(y_pred=pred,y_true=multi_y_test))
#各个分类的精准度、召回率、f1-score 、支持率
#具体含义请参考：https://blog.csdn.net/akadiao/article/details/78788864
```

                  precision    recall  f1-score   support
    
               0       0.69      0.71      0.70       153
               1       0.05      0.08      0.06        12
               2       0.10      0.20      0.13        10
               3       0.77      0.68      0.72       291
               4       0.00      0.00      0.00         9
               5       0.45      0.46      0.46        41
               6       0.26      0.38      0.31        16
    
       micro avg       0.63      0.63      0.63       532
       macro avg       0.33      0.36      0.34       532
    weighted avg       0.66      0.63      0.64       532
    



```python
#混淆矩阵及其可视化
def plot_confusion_matrix(cm, title='Confusion Matrix', cmap = plt.cm.binary):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
cm = confusion_matrix(y_true=multi_y_test, y_pred=pred)
print(cm)
plot_confusion_matrix(cm)
#右斜对角线表示分对的样本，越深样本越多，表示分类情况越好
```

    [[108   4   1  32   3   4   1]
     [  4   1   3   4   0   0   0]
     [  0   1   2   7   0   0   0]
     [ 31  13  13 197   5  16  16]
     [  1   1   0   7   0   0   0]
     [ 10   2   1   5   4  19   0]
     [  3   0   0   4   0   3   6]]



![png](output_50_1.png)



```python

```



## 参考文献

[1][Lasso回归](https://blog.csdn.net/xiaozhu_1024/article/details/80585151)

[2][Model_Selection_and_Regularization](https://jiamingmao.github.io/data-analysis/assets/Lectures/Model_Selection_and_Regularization.pdf)

[3][Lasso regression(稀疏学习,R)](https://blog.csdn.net/hfutxiaoguozhi/article/details/78847040)

[4][什么是正则化](https://blog.csdn.net/haima1998/article/details/79425831)
